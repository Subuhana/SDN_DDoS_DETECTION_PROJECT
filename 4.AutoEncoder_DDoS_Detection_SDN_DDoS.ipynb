{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WgrndRzPeMsM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
        "from tensorflow.keras.losses import MeanSquaredError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "yYnLpe-5eW5B",
        "outputId": "37666161-f7af-49fe-96d8-4e30e804c0f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-894335ef-34a4-47f2-9f3d-dfc312fc354c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dt</th>\n",
              "      <th>switch</th>\n",
              "      <th>src</th>\n",
              "      <th>dst</th>\n",
              "      <th>pktcount</th>\n",
              "      <th>bytecount</th>\n",
              "      <th>dur</th>\n",
              "      <th>dur_nsec</th>\n",
              "      <th>tot_dur</th>\n",
              "      <th>flows</th>\n",
              "      <th>packetins</th>\n",
              "      <th>pktperflow</th>\n",
              "      <th>byteperflow</th>\n",
              "      <th>pktrate</th>\n",
              "      <th>Pairflow</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>port_no</th>\n",
              "      <th>tx_bytes</th>\n",
              "      <th>rx_bytes</th>\n",
              "      <th>tx_kbps</th>\n",
              "      <th>rx_kbps</th>\n",
              "      <th>tot_kbps</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11425</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0.0.1</td>\n",
              "      <td>10.0.0.8</td>\n",
              "      <td>45304</td>\n",
              "      <td>48294064</td>\n",
              "      <td>100</td>\n",
              "      <td>716000000</td>\n",
              "      <td>1.010000e+11</td>\n",
              "      <td>3</td>\n",
              "      <td>1943</td>\n",
              "      <td>13535</td>\n",
              "      <td>14428310</td>\n",
              "      <td>451</td>\n",
              "      <td>0</td>\n",
              "      <td>UDP</td>\n",
              "      <td>3</td>\n",
              "      <td>143928631</td>\n",
              "      <td>3917</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11605</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0.0.1</td>\n",
              "      <td>10.0.0.8</td>\n",
              "      <td>126395</td>\n",
              "      <td>134737070</td>\n",
              "      <td>280</td>\n",
              "      <td>734000000</td>\n",
              "      <td>2.810000e+11</td>\n",
              "      <td>2</td>\n",
              "      <td>1943</td>\n",
              "      <td>13531</td>\n",
              "      <td>14424046</td>\n",
              "      <td>451</td>\n",
              "      <td>0</td>\n",
              "      <td>UDP</td>\n",
              "      <td>4</td>\n",
              "      <td>3842</td>\n",
              "      <td>3520</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11425</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0.0.2</td>\n",
              "      <td>10.0.0.8</td>\n",
              "      <td>90333</td>\n",
              "      <td>96294978</td>\n",
              "      <td>200</td>\n",
              "      <td>744000000</td>\n",
              "      <td>2.010000e+11</td>\n",
              "      <td>3</td>\n",
              "      <td>1943</td>\n",
              "      <td>13534</td>\n",
              "      <td>14427244</td>\n",
              "      <td>451</td>\n",
              "      <td>0</td>\n",
              "      <td>UDP</td>\n",
              "      <td>1</td>\n",
              "      <td>3795</td>\n",
              "      <td>1242</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11425</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0.0.2</td>\n",
              "      <td>10.0.0.8</td>\n",
              "      <td>90333</td>\n",
              "      <td>96294978</td>\n",
              "      <td>200</td>\n",
              "      <td>744000000</td>\n",
              "      <td>2.010000e+11</td>\n",
              "      <td>3</td>\n",
              "      <td>1943</td>\n",
              "      <td>13534</td>\n",
              "      <td>14427244</td>\n",
              "      <td>451</td>\n",
              "      <td>0</td>\n",
              "      <td>UDP</td>\n",
              "      <td>2</td>\n",
              "      <td>3688</td>\n",
              "      <td>1492</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11425</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0.0.2</td>\n",
              "      <td>10.0.0.8</td>\n",
              "      <td>90333</td>\n",
              "      <td>96294978</td>\n",
              "      <td>200</td>\n",
              "      <td>744000000</td>\n",
              "      <td>2.010000e+11</td>\n",
              "      <td>3</td>\n",
              "      <td>1943</td>\n",
              "      <td>13534</td>\n",
              "      <td>14427244</td>\n",
              "      <td>451</td>\n",
              "      <td>0</td>\n",
              "      <td>UDP</td>\n",
              "      <td>3</td>\n",
              "      <td>3413</td>\n",
              "      <td>3665</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-894335ef-34a4-47f2-9f3d-dfc312fc354c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-894335ef-34a4-47f2-9f3d-dfc312fc354c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-894335ef-34a4-47f2-9f3d-dfc312fc354c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      dt  switch       src       dst  ...  tx_kbps  rx_kbps  tot_kbps  label\n",
              "0  11425       1  10.0.0.1  10.0.0.8  ...        0      0.0       0.0      0\n",
              "1  11605       1  10.0.0.1  10.0.0.8  ...        0      0.0       0.0      0\n",
              "2  11425       1  10.0.0.2  10.0.0.8  ...        0      0.0       0.0      0\n",
              "3  11425       1  10.0.0.2  10.0.0.8  ...        0      0.0       0.0      0\n",
              "4  11425       1  10.0.0.2  10.0.0.8  ...        0      0.0       0.0      0\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# load the dataset\n",
        "DDoS = pd.read_csv('/content/dataset_sdn.csv')\n",
        "DDoS.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DDoS.Protocol.unique()\n",
        "DDoS['Protocol'] = DDoS['Protocol'].replace('TCP', '0')\n",
        "DDoS['Protocol'] = DDoS['Protocol'].replace('UDP', '1')\n",
        "DDoS['Protocol'] = DDoS['Protocol'].replace('ICMP', '2')\n",
        "DDoS.Protocol.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-l1CUIGHaVn",
        "outputId": "a58a7745-34a4-4b90-8900-71e5f8660e04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '0', '2'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DDoS[\"rx_kbps\"] = DDoS[\"rx_kbps\"].fillna(DDoS[\"rx_kbps\"].mean())"
      ],
      "metadata": {
        "id": "VZcRsTI6HiEh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DDoS[\"tot_kbps\"] = DDoS[\"tot_kbps\"].fillna(DDoS[\"tot_kbps\"].mean())"
      ],
      "metadata": {
        "id": "oMdaa9W1HlYH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DDoS.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaS02wAuHocI",
        "outputId": "2769c921-f884-46b8-deb5-f097d9daf678"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dt             0\n",
              "switch         0\n",
              "src            0\n",
              "dst            0\n",
              "pktcount       0\n",
              "bytecount      0\n",
              "dur            0\n",
              "dur_nsec       0\n",
              "tot_dur        0\n",
              "flows          0\n",
              "packetins      0\n",
              "pktperflow     0\n",
              "byteperflow    0\n",
              "pktrate        0\n",
              "Pairflow       0\n",
              "Protocol       0\n",
              "port_no        0\n",
              "tx_bytes       0\n",
              "rx_bytes       0\n",
              "tx_kbps        0\n",
              "rx_kbps        0\n",
              "tot_kbps       0\n",
              "label          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pWAM52FbeavO"
      },
      "outputs": [],
      "source": [
        "features = DDoS[['dt', 'switch', 'pktcount', 'bytecount', 'dur', 'tot_dur',\n",
        "       'flows', 'packetins', 'pktperflow', 'byteperflow', 'pktrate',\n",
        "       'Pairflow','Protocol' ,'port_no', 'tx_bytes', 'rx_bytes', 'tx_kbps', 'rx_kbps',\n",
        "       'tot_kbps']]\n",
        "target = DDoS['label']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    features, target, test_size=0.2, stratify=target\n",
        ")\n",
        "\n",
        "# use case is novelty detection so use only the normal data\n",
        "# for training\n",
        "train_index = y_train[y_train == 0].index\n",
        "train_data = x_train.loc[train_index]\n",
        "\n",
        "# min max scale the input data\n",
        "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "x_train_scaled = min_max_scaler.fit_transform(train_data.copy())\n",
        "x_test_scaled = min_max_scaler.transform(x_test.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTb7EPBNegG2",
        "outputId": "03c0c988-fe94-4956-c22f-7d2570ea48fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3179/3179 [==============================] - 22s 6ms/step - loss: 0.0259 - accuracy: 0.5299 - val_loss: 0.0192 - val_accuracy: 0.8130\n",
            "Epoch 2/200\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0159 - accuracy: 0.6814 - val_loss: 0.0172 - val_accuracy: 0.8311\n",
            "Epoch 3/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0142 - accuracy: 0.6974 - val_loss: 0.0162 - val_accuracy: 0.8072\n",
            "Epoch 4/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0133 - accuracy: 0.7154 - val_loss: 0.0159 - val_accuracy: 0.8389\n",
            "Epoch 5/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0128 - accuracy: 0.7487 - val_loss: 0.0156 - val_accuracy: 0.8515\n",
            "Epoch 6/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0126 - accuracy: 0.7693 - val_loss: 0.0152 - val_accuracy: 0.8536\n",
            "Epoch 7/200\n",
            "3179/3179 [==============================] - 15s 5ms/step - loss: 0.0124 - accuracy: 0.7659 - val_loss: 0.0152 - val_accuracy: 0.8297\n",
            "Epoch 8/200\n",
            "3179/3179 [==============================] - 16s 5ms/step - loss: 0.0123 - accuracy: 0.7753 - val_loss: 0.0156 - val_accuracy: 0.8792\n",
            "Epoch 9/200\n",
            "3179/3179 [==============================] - 19s 6ms/step - loss: 0.0122 - accuracy: 0.7783 - val_loss: 0.0154 - val_accuracy: 0.8401\n",
            "Epoch 10/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0121 - accuracy: 0.7661 - val_loss: 0.0151 - val_accuracy: 0.8683\n",
            "Epoch 11/200\n",
            "3179/3179 [==============================] - 13s 4ms/step - loss: 0.0121 - accuracy: 0.7640 - val_loss: 0.0154 - val_accuracy: 0.8276\n",
            "Epoch 12/200\n",
            "3179/3179 [==============================] - 18s 6ms/step - loss: 0.0120 - accuracy: 0.7725 - val_loss: 0.0150 - val_accuracy: 0.8371\n",
            "Epoch 13/200\n",
            "3179/3179 [==============================] - 14s 5ms/step - loss: 0.0119 - accuracy: 0.7740 - val_loss: 0.0150 - val_accuracy: 0.8330\n",
            "Epoch 14/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0118 - accuracy: 0.7766 - val_loss: 0.0144 - val_accuracy: 0.8401\n",
            "Epoch 15/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0118 - accuracy: 0.7801 - val_loss: 0.0144 - val_accuracy: 0.8020\n",
            "Epoch 16/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0117 - accuracy: 0.7566 - val_loss: 0.0145 - val_accuracy: 0.8217\n",
            "Epoch 17/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0116 - accuracy: 0.7461 - val_loss: 0.0146 - val_accuracy: 0.8038\n",
            "Epoch 18/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0116 - accuracy: 0.7236 - val_loss: 0.0145 - val_accuracy: 0.7913\n",
            "Epoch 19/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0115 - accuracy: 0.7342 - val_loss: 0.0139 - val_accuracy: 0.7181\n",
            "Epoch 20/200\n",
            "3179/3179 [==============================] - 15s 5ms/step - loss: 0.0114 - accuracy: 0.7461 - val_loss: 0.0143 - val_accuracy: 0.7824\n",
            "Epoch 21/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0114 - accuracy: 0.7300 - val_loss: 0.0144 - val_accuracy: 0.7928\n",
            "Epoch 22/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0113 - accuracy: 0.7150 - val_loss: 0.0141 - val_accuracy: 0.7842\n",
            "Epoch 23/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0113 - accuracy: 0.7234 - val_loss: 0.0142 - val_accuracy: 0.7603\n",
            "Epoch 24/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0113 - accuracy: 0.7050 - val_loss: 0.0145 - val_accuracy: 0.7495\n",
            "Epoch 25/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0114 - accuracy: 0.7035 - val_loss: 0.0141 - val_accuracy: 0.7801\n",
            "Epoch 26/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0113 - accuracy: 0.7107 - val_loss: 0.0143 - val_accuracy: 0.7578\n",
            "Epoch 27/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0112 - accuracy: 0.7255 - val_loss: 0.0140 - val_accuracy: 0.7690\n",
            "Epoch 28/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0111 - accuracy: 0.7147 - val_loss: 0.0139 - val_accuracy: 0.7651\n",
            "Epoch 29/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0112 - accuracy: 0.7186 - val_loss: 0.0140 - val_accuracy: 0.7794\n",
            "Epoch 30/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0111 - accuracy: 0.7221 - val_loss: 0.0142 - val_accuracy: 0.7861\n",
            "Epoch 31/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0112 - accuracy: 0.7548 - val_loss: 0.0146 - val_accuracy: 0.8357\n",
            "Epoch 32/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0110 - accuracy: 0.7554 - val_loss: 0.0142 - val_accuracy: 0.8037\n",
            "Epoch 33/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0110 - accuracy: 0.7371 - val_loss: 0.0141 - val_accuracy: 0.8278\n",
            "Epoch 34/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0110 - accuracy: 0.7301 - val_loss: 0.0143 - val_accuracy: 0.7666\n",
            "Epoch 35/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0110 - accuracy: 0.7459 - val_loss: 0.0140 - val_accuracy: 0.7825\n",
            "Epoch 36/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0110 - accuracy: 0.7672 - val_loss: 0.0144 - val_accuracy: 0.7837\n",
            "Epoch 37/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0109 - accuracy: 0.7643 - val_loss: 0.0144 - val_accuracy: 0.7913\n",
            "Epoch 38/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0108 - accuracy: 0.7774 - val_loss: 0.0143 - val_accuracy: 0.7425\n",
            "Epoch 39/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0108 - accuracy: 0.7759 - val_loss: 0.0143 - val_accuracy: 0.7862\n",
            "Epoch 40/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0108 - accuracy: 0.7563 - val_loss: 0.0139 - val_accuracy: 0.8216\n",
            "Epoch 41/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0107 - accuracy: 0.7606 - val_loss: 0.0143 - val_accuracy: 0.8125\n",
            "Epoch 42/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0108 - accuracy: 0.7599 - val_loss: 0.0137 - val_accuracy: 0.8286\n",
            "Epoch 43/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0106 - accuracy: 0.7594 - val_loss: 0.0140 - val_accuracy: 0.8109\n",
            "Epoch 44/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0107 - accuracy: 0.7467 - val_loss: 0.0138 - val_accuracy: 0.8117\n",
            "Epoch 45/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0106 - accuracy: 0.7736 - val_loss: 0.0141 - val_accuracy: 0.8088\n",
            "Epoch 46/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0106 - accuracy: 0.7473 - val_loss: 0.0143 - val_accuracy: 0.8308\n",
            "Epoch 47/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0106 - accuracy: 0.7751 - val_loss: 0.0142 - val_accuracy: 0.8127\n",
            "Epoch 48/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0106 - accuracy: 0.7430 - val_loss: 0.0142 - val_accuracy: 0.7820\n",
            "Epoch 49/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0106 - accuracy: 0.7235 - val_loss: 0.0141 - val_accuracy: 0.7979\n",
            "Epoch 50/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0106 - accuracy: 0.7208 - val_loss: 0.0142 - val_accuracy: 0.7957\n",
            "Epoch 51/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0105 - accuracy: 0.7374 - val_loss: 0.0138 - val_accuracy: 0.7846\n",
            "Epoch 52/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0106 - accuracy: 0.7259 - val_loss: 0.0142 - val_accuracy: 0.7791\n",
            "Epoch 53/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0104 - accuracy: 0.7063 - val_loss: 0.0138 - val_accuracy: 0.7574\n",
            "Epoch 54/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0104 - accuracy: 0.7082 - val_loss: 0.0141 - val_accuracy: 0.7619\n",
            "Epoch 55/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0105 - accuracy: 0.7189 - val_loss: 0.0139 - val_accuracy: 0.7586\n",
            "Epoch 56/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0104 - accuracy: 0.7177 - val_loss: 0.0141 - val_accuracy: 0.7438\n",
            "Epoch 57/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0105 - accuracy: 0.6917 - val_loss: 0.0139 - val_accuracy: 0.7416\n",
            "Epoch 58/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0104 - accuracy: 0.7159 - val_loss: 0.0140 - val_accuracy: 0.7530\n",
            "Epoch 59/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0104 - accuracy: 0.7489 - val_loss: 0.0146 - val_accuracy: 0.8101\n",
            "Epoch 60/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0103 - accuracy: 0.7347 - val_loss: 0.0138 - val_accuracy: 0.7766\n",
            "Epoch 61/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0103 - accuracy: 0.7458 - val_loss: 0.0149 - val_accuracy: 0.7954\n",
            "Epoch 62/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0103 - accuracy: 0.7464 - val_loss: 0.0142 - val_accuracy: 0.7964\n",
            "Epoch 63/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0103 - accuracy: 0.7482 - val_loss: 0.0142 - val_accuracy: 0.7975\n",
            "Epoch 64/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0103 - accuracy: 0.7596 - val_loss: 0.0142 - val_accuracy: 0.8610\n",
            "Epoch 65/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0105 - accuracy: 0.7663 - val_loss: 0.0141 - val_accuracy: 0.8067\n",
            "Epoch 66/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0103 - accuracy: 0.7625 - val_loss: 0.0144 - val_accuracy: 0.7806\n",
            "Epoch 67/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0102 - accuracy: 0.7597 - val_loss: 0.0141 - val_accuracy: 0.8006\n",
            "Epoch 68/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0103 - accuracy: 0.7688 - val_loss: 0.0139 - val_accuracy: 0.7911\n",
            "Epoch 69/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0102 - accuracy: 0.7901 - val_loss: 0.0139 - val_accuracy: 0.8121\n",
            "Epoch 70/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0103 - accuracy: 0.7788 - val_loss: 0.0143 - val_accuracy: 0.8596\n",
            "Epoch 71/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0102 - accuracy: 0.7877 - val_loss: 0.0142 - val_accuracy: 0.8080\n",
            "Epoch 72/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0102 - accuracy: 0.7791 - val_loss: 0.0144 - val_accuracy: 0.7966\n",
            "Epoch 73/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0102 - accuracy: 0.7866 - val_loss: 0.0147 - val_accuracy: 0.7796\n",
            "Epoch 74/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0103 - accuracy: 0.7549 - val_loss: 0.0146 - val_accuracy: 0.7641\n",
            "Epoch 75/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0103 - accuracy: 0.7777 - val_loss: 0.0144 - val_accuracy: 0.8226\n",
            "Epoch 76/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0102 - accuracy: 0.7715 - val_loss: 0.0143 - val_accuracy: 0.8021\n",
            "Epoch 77/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0102 - accuracy: 0.7666 - val_loss: 0.0146 - val_accuracy: 0.7914\n",
            "Epoch 78/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0101 - accuracy: 0.7661 - val_loss: 0.0148 - val_accuracy: 0.8524\n",
            "Epoch 79/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0101 - accuracy: 0.7851 - val_loss: 0.0148 - val_accuracy: 0.7910\n",
            "Epoch 80/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0102 - accuracy: 0.7665 - val_loss: 0.0145 - val_accuracy: 0.8007\n",
            "Epoch 81/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0101 - accuracy: 0.7747 - val_loss: 0.0143 - val_accuracy: 0.7969\n",
            "Epoch 82/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0102 - accuracy: 0.7779 - val_loss: 0.0142 - val_accuracy: 0.8036\n",
            "Epoch 83/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0101 - accuracy: 0.7919 - val_loss: 0.0147 - val_accuracy: 0.8374\n",
            "Epoch 84/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0101 - accuracy: 0.8148 - val_loss: 0.0145 - val_accuracy: 0.8150\n",
            "Epoch 85/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0103 - accuracy: 0.8024 - val_loss: 0.0147 - val_accuracy: 0.8392\n",
            "Epoch 86/200\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0101 - accuracy: 0.8255 - val_loss: 0.0146 - val_accuracy: 0.8810\n",
            "Epoch 87/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0102 - accuracy: 0.7969 - val_loss: 0.0145 - val_accuracy: 0.8029\n",
            "Epoch 88/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0102 - accuracy: 0.8040 - val_loss: 0.0149 - val_accuracy: 0.8419\n",
            "Epoch 89/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0101 - accuracy: 0.7978 - val_loss: 0.0143 - val_accuracy: 0.8068\n",
            "Epoch 90/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0101 - accuracy: 0.7510 - val_loss: 0.0144 - val_accuracy: 0.8432\n",
            "Epoch 91/200\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0100 - accuracy: 0.7877 - val_loss: 0.0151 - val_accuracy: 0.8291\n",
            "Epoch 92/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0101 - accuracy: 0.7931 - val_loss: 0.0144 - val_accuracy: 0.8470\n",
            "Epoch 93/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0101 - accuracy: 0.8229 - val_loss: 0.0155 - val_accuracy: 0.8286\n",
            "Epoch 94/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0100 - accuracy: 0.7996 - val_loss: 0.0151 - val_accuracy: 0.8057\n",
            "Epoch 95/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0100 - accuracy: 0.7912 - val_loss: 0.0147 - val_accuracy: 0.8699\n",
            "Epoch 96/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0100 - accuracy: 0.8140 - val_loss: 0.0147 - val_accuracy: 0.8392\n",
            "Epoch 97/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0099 - accuracy: 0.8330 - val_loss: 0.0146 - val_accuracy: 0.8580\n",
            "Epoch 98/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0100 - accuracy: 0.8171 - val_loss: 0.0141 - val_accuracy: 0.8500\n",
            "Epoch 99/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0101 - accuracy: 0.8123 - val_loss: 0.0146 - val_accuracy: 0.8606\n",
            "Epoch 100/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0100 - accuracy: 0.8313 - val_loss: 0.0146 - val_accuracy: 0.8655\n",
            "Epoch 101/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0099 - accuracy: 0.8074 - val_loss: 0.0157 - val_accuracy: 0.8539\n",
            "Epoch 102/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0101 - accuracy: 0.8129 - val_loss: 0.0148 - val_accuracy: 0.8235\n",
            "Epoch 103/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0099 - accuracy: 0.8360 - val_loss: 0.0148 - val_accuracy: 0.8872\n",
            "Epoch 104/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0099 - accuracy: 0.8550 - val_loss: 0.0148 - val_accuracy: 0.8991\n",
            "Epoch 105/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0099 - accuracy: 0.8471 - val_loss: 0.0152 - val_accuracy: 0.8815\n",
            "Epoch 106/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0100 - accuracy: 0.8431 - val_loss: 0.0145 - val_accuracy: 0.8700\n",
            "Epoch 107/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0100 - accuracy: 0.8342 - val_loss: 0.0144 - val_accuracy: 0.8676\n",
            "Epoch 108/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0098 - accuracy: 0.8485 - val_loss: 0.0149 - val_accuracy: 0.8366\n",
            "Epoch 109/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0099 - accuracy: 0.8237 - val_loss: 0.0142 - val_accuracy: 0.8585\n",
            "Epoch 110/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0100 - accuracy: 0.8248 - val_loss: 0.0140 - val_accuracy: 0.8741\n",
            "Epoch 111/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0099 - accuracy: 0.8529 - val_loss: 0.0143 - val_accuracy: 0.8630\n",
            "Epoch 112/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0099 - accuracy: 0.8660 - val_loss: 0.0142 - val_accuracy: 0.9054\n",
            "Epoch 113/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0099 - accuracy: 0.8757 - val_loss: 0.0140 - val_accuracy: 0.8831\n",
            "Epoch 114/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0099 - accuracy: 0.8626 - val_loss: 0.0142 - val_accuracy: 0.8863\n",
            "Epoch 115/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0099 - accuracy: 0.8544 - val_loss: 0.0148 - val_accuracy: 0.8872\n",
            "Epoch 116/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0099 - accuracy: 0.8371 - val_loss: 0.0148 - val_accuracy: 0.8673\n",
            "Epoch 117/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0100 - accuracy: 0.8666 - val_loss: 0.0150 - val_accuracy: 0.8739\n",
            "Epoch 118/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0100 - accuracy: 0.8507 - val_loss: 0.0143 - val_accuracy: 0.8941\n",
            "Epoch 119/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0100 - accuracy: 0.8463 - val_loss: 0.0148 - val_accuracy: 0.8958\n",
            "Epoch 120/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0099 - accuracy: 0.8703 - val_loss: 0.0148 - val_accuracy: 0.9047\n",
            "Epoch 121/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0098 - accuracy: 0.8690 - val_loss: 0.0148 - val_accuracy: 0.8792\n",
            "Epoch 122/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0098 - accuracy: 0.8482 - val_loss: 0.0147 - val_accuracy: 0.8870\n",
            "Epoch 123/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0099 - accuracy: 0.8582 - val_loss: 0.0143 - val_accuracy: 0.8982\n",
            "Epoch 124/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0099 - accuracy: 0.8762 - val_loss: 0.0141 - val_accuracy: 0.9149\n",
            "Epoch 125/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0099 - accuracy: 0.8726 - val_loss: 0.0147 - val_accuracy: 0.9014\n",
            "Epoch 126/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0099 - accuracy: 0.8708 - val_loss: 0.0142 - val_accuracy: 0.8915\n",
            "Epoch 127/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0098 - accuracy: 0.8715 - val_loss: 0.0139 - val_accuracy: 0.9195\n",
            "Epoch 128/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0097 - accuracy: 0.8681 - val_loss: 0.0142 - val_accuracy: 0.8637\n",
            "Epoch 129/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0098 - accuracy: 0.8687 - val_loss: 0.0145 - val_accuracy: 0.9084\n",
            "Epoch 130/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0098 - accuracy: 0.8749 - val_loss: 0.0138 - val_accuracy: 0.8723\n",
            "Epoch 131/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0097 - accuracy: 0.8394 - val_loss: 0.0136 - val_accuracy: 0.8904\n",
            "Epoch 132/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0098 - accuracy: 0.8539 - val_loss: 0.0146 - val_accuracy: 0.8833\n",
            "Epoch 133/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0097 - accuracy: 0.8425 - val_loss: 0.0139 - val_accuracy: 0.8980\n",
            "Epoch 134/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0097 - accuracy: 0.8731 - val_loss: 0.0143 - val_accuracy: 0.9026\n",
            "Epoch 135/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0097 - accuracy: 0.8812 - val_loss: 0.0150 - val_accuracy: 0.8970\n",
            "Epoch 136/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0098 - accuracy: 0.8885 - val_loss: 0.0143 - val_accuracy: 0.9039\n",
            "Epoch 137/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0097 - accuracy: 0.8831 - val_loss: 0.0141 - val_accuracy: 0.9163\n",
            "Epoch 138/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0098 - accuracy: 0.8827 - val_loss: 0.0148 - val_accuracy: 0.8992\n",
            "Epoch 139/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0097 - accuracy: 0.8982 - val_loss: 0.0144 - val_accuracy: 0.9161\n",
            "Epoch 140/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0097 - accuracy: 0.8898 - val_loss: 0.0152 - val_accuracy: 0.9119\n",
            "Epoch 141/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0097 - accuracy: 0.8848 - val_loss: 0.0133 - val_accuracy: 0.9239\n",
            "Epoch 142/200\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0096 - accuracy: 0.8900 - val_loss: 0.0150 - val_accuracy: 0.9177\n",
            "Epoch 143/200\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0096 - accuracy: 0.8927 - val_loss: 0.0151 - val_accuracy: 0.8921\n",
            "Epoch 144/200\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0096 - accuracy: 0.8712 - val_loss: 0.0146 - val_accuracy: 0.8992\n",
            "Epoch 145/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.8877 - val_loss: 0.0152 - val_accuracy: 0.8895\n",
            "Epoch 146/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0096 - accuracy: 0.8989 - val_loss: 0.0138 - val_accuracy: 0.9207\n",
            "Epoch 147/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0096 - accuracy: 0.8986 - val_loss: 0.0135 - val_accuracy: 0.9243\n",
            "Epoch 148/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0096 - accuracy: 0.9005 - val_loss: 0.0148 - val_accuracy: 0.8996\n",
            "Epoch 149/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0096 - accuracy: 0.9014 - val_loss: 0.0144 - val_accuracy: 0.9067\n",
            "Epoch 150/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0095 - accuracy: 0.8950 - val_loss: 0.0136 - val_accuracy: 0.9182\n",
            "Epoch 151/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0095 - accuracy: 0.9012 - val_loss: 0.0139 - val_accuracy: 0.9108\n",
            "Epoch 152/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0095 - accuracy: 0.9060 - val_loss: 0.0145 - val_accuracy: 0.9127\n",
            "Epoch 153/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.9030 - val_loss: 0.0140 - val_accuracy: 0.9134\n",
            "Epoch 154/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.9036 - val_loss: 0.0141 - val_accuracy: 0.8939\n",
            "Epoch 155/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0096 - accuracy: 0.8996 - val_loss: 0.0139 - val_accuracy: 0.9249\n",
            "Epoch 156/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0096 - accuracy: 0.9057 - val_loss: 0.0138 - val_accuracy: 0.9122\n",
            "Epoch 157/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.8957 - val_loss: 0.0151 - val_accuracy: 0.8889\n",
            "Epoch 158/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0096 - accuracy: 0.8995 - val_loss: 0.0153 - val_accuracy: 0.8922\n",
            "Epoch 159/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0096 - accuracy: 0.9026 - val_loss: 0.0153 - val_accuracy: 0.8812\n",
            "Epoch 160/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0095 - accuracy: 0.9037 - val_loss: 0.0146 - val_accuracy: 0.8985\n",
            "Epoch 161/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0095 - accuracy: 0.9038 - val_loss: 0.0143 - val_accuracy: 0.9080\n",
            "Epoch 162/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0095 - accuracy: 0.9002 - val_loss: 0.0144 - val_accuracy: 0.8834\n",
            "Epoch 163/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0097 - accuracy: 0.9027 - val_loss: 0.0145 - val_accuracy: 0.9029\n",
            "Epoch 164/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0096 - accuracy: 0.9067 - val_loss: 0.0150 - val_accuracy: 0.9111\n",
            "Epoch 165/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.9102 - val_loss: 0.0140 - val_accuracy: 0.9302\n",
            "Epoch 166/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0094 - accuracy: 0.9077 - val_loss: 0.0152 - val_accuracy: 0.9151\n",
            "Epoch 167/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0096 - accuracy: 0.9001 - val_loss: 0.0150 - val_accuracy: 0.8936\n",
            "Epoch 168/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0096 - accuracy: 0.9104 - val_loss: 0.0151 - val_accuracy: 0.9213\n",
            "Epoch 169/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0096 - accuracy: 0.8992 - val_loss: 0.0149 - val_accuracy: 0.8989\n",
            "Epoch 170/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0095 - accuracy: 0.9045 - val_loss: 0.0156 - val_accuracy: 0.8994\n",
            "Epoch 171/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0096 - accuracy: 0.9016 - val_loss: 0.0154 - val_accuracy: 0.9047\n",
            "Epoch 172/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0096 - accuracy: 0.9012 - val_loss: 0.0149 - val_accuracy: 0.9042\n",
            "Epoch 173/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.8994 - val_loss: 0.0149 - val_accuracy: 0.8996\n",
            "Epoch 174/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0096 - accuracy: 0.9002 - val_loss: 0.0148 - val_accuracy: 0.9028\n",
            "Epoch 175/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0094 - accuracy: 0.9004 - val_loss: 0.0149 - val_accuracy: 0.8842\n",
            "Epoch 176/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0096 - accuracy: 0.9055 - val_loss: 0.0148 - val_accuracy: 0.9000\n",
            "Epoch 177/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.9093 - val_loss: 0.0146 - val_accuracy: 0.9013\n",
            "Epoch 178/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0096 - accuracy: 0.9075 - val_loss: 0.0147 - val_accuracy: 0.9092\n",
            "Epoch 179/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0096 - accuracy: 0.9078 - val_loss: 0.0146 - val_accuracy: 0.9088\n",
            "Epoch 180/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0094 - accuracy: 0.9083 - val_loss: 0.0145 - val_accuracy: 0.9096\n",
            "Epoch 181/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0096 - accuracy: 0.9019 - val_loss: 0.0145 - val_accuracy: 0.9044\n",
            "Epoch 182/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.8967 - val_loss: 0.0150 - val_accuracy: 0.9088\n",
            "Epoch 183/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.9027 - val_loss: 0.0150 - val_accuracy: 0.9002\n",
            "Epoch 184/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0098 - accuracy: 0.9017 - val_loss: 0.0148 - val_accuracy: 0.8923\n",
            "Epoch 185/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0096 - accuracy: 0.9022 - val_loss: 0.0148 - val_accuracy: 0.9066\n",
            "Epoch 186/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0094 - accuracy: 0.8993 - val_loss: 0.0153 - val_accuracy: 0.8971\n",
            "Epoch 187/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.9027 - val_loss: 0.0159 - val_accuracy: 0.8773\n",
            "Epoch 188/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.9038 - val_loss: 0.0148 - val_accuracy: 0.9077\n",
            "Epoch 189/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.9010 - val_loss: 0.0145 - val_accuracy: 0.8990\n",
            "Epoch 190/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0094 - accuracy: 0.8990 - val_loss: 0.0149 - val_accuracy: 0.8987\n",
            "Epoch 191/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0097 - accuracy: 0.9036 - val_loss: 0.0148 - val_accuracy: 0.9016\n",
            "Epoch 192/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0094 - accuracy: 0.8956 - val_loss: 0.0141 - val_accuracy: 0.9209\n",
            "Epoch 193/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0094 - accuracy: 0.9024 - val_loss: 0.0141 - val_accuracy: 0.9156\n",
            "Epoch 194/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0095 - accuracy: 0.8993 - val_loss: 0.0142 - val_accuracy: 0.8966\n",
            "Epoch 195/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0094 - accuracy: 0.9007 - val_loss: 0.0148 - val_accuracy: 0.8794\n",
            "Epoch 196/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0094 - accuracy: 0.9036 - val_loss: 0.0145 - val_accuracy: 0.8799\n",
            "Epoch 197/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0094 - accuracy: 0.9030 - val_loss: 0.0151 - val_accuracy: 0.9072\n",
            "Epoch 198/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0096 - accuracy: 0.9014 - val_loss: 0.0151 - val_accuracy: 0.8946\n",
            "Epoch 199/200\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0097 - accuracy: 0.9064 - val_loss: 0.0148 - val_accuracy: 0.9044\n",
            "Epoch 200/200\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0095 - accuracy: 0.8978 - val_loss: 0.0146 - val_accuracy: 0.8861\n"
          ]
        }
      ],
      "source": [
        "class AutoEncoder(Model):\n",
        "  def __init__(self, output_units, code_size=16):\n",
        "    super().__init__()\n",
        "    self.encoder = Sequential([\n",
        "      Dense(20, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(16, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(code_size, activation='relu')\n",
        "    ])\n",
        "    self.decoder = Sequential([\n",
        "      Dense(16, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(32, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(20, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(output_units, activation='sigmoid')\n",
        "    ])\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    encoded = self.encoder(inputs)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "  \n",
        "model = AutoEncoder(output_units=x_train_scaled.shape[1])\n",
        "# configurations of model\n",
        "model.compile(loss='mse', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "history = model.fit(\n",
        "    x_train_scaled,\n",
        "    x_train_scaled,\n",
        "    epochs=200,\n",
        "    batch_size=16,\n",
        "    validation_data=(x_test_scaled, x_test_scaled)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "x_ZizsW7fduI",
        "outputId": "59740ea9-a417-402c-caeb-59bb4f440a36"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DrfThARfh90",
        "outputId": "e5315e7c-94ad-4a3e-ec7d-63f4ad535181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold: 0.007815301966076106\n"
          ]
        }
      ],
      "source": [
        "def find_threshold(model, x_train_scaled):\n",
        "  reconstructions = model.predict(x_train_scaled)\n",
        "  # provides losses of individual instances\n",
        "  reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n",
        "  # threshold for anomaly scores\n",
        "  threshold = np.mean(reconstruction_errors.numpy()) + np.std(reconstruction_errors.numpy())\n",
        "  return threshold\n",
        "\n",
        "def get_predictions(model, x_test_scaled, threshold):\n",
        "  predictions = model.predict(x_test_scaled)\n",
        "  # provides losses of individual instances\n",
        "  errors = tf.keras.losses.msle(predictions, x_test_scaled)\n",
        "  \n",
        "  anomaly_mask = pd.Series(errors) > threshold\n",
        "  preds = anomaly_mask.map(lambda x: 1.0 if x == True else 0.0)\n",
        "  return preds\n",
        "\n",
        "threshold = find_threshold(model, x_train_scaled)\n",
        "print(f\"Threshold: {threshold}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYCEb73WfvwX",
        "outputId": "7abfac11-4e25-4b52-e955-dde18b50eb64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6827830753749581"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "predictions = get_predictions(model, x_test_scaled, threshold)\n",
        "accuracy_score(y_test,predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y72EQaayg0cl",
        "outputId": "3e2d2ff7-38cd-4968-b431-cb160f40b1bd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n",
            "\u001b[?25l\r\u001b[K     |                            | 10 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |                         | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |                      | 30 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |                  | 40 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |               | 51 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |            | 61 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |        | 71 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |     | 81 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |  | 92 kB 15.8 MB/s eta 0:00:01\r\u001b[K     || 98 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.7.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.43.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.0 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kerastuner as kt\n",
        "\n",
        "class AutoEncoderTuner(Model):\n",
        "\n",
        "  def __init__(self, hp, output_units, code_size=8):\n",
        "    super().__init__()\n",
        "    dense_1_units = hp.Int('dense_1_units', min_value=16, max_value=72, step=4)\n",
        "    dense_2_units = hp.Int('dense_2_units', min_value=16, max_value=72, step=4)\n",
        "    dense_3_units = hp.Int('dense_3_units', min_value=16, max_value=72, step=4)\n",
        "    dense_4_units = hp.Int('dense_4_units', min_value=16, max_value=72, step=4)\n",
        "    dense_5_units = hp.Int('dense_5_units', min_value=16, max_value=72, step=4)\n",
        "    dense_6_units = hp.Int('dense_6_units', min_value=16, max_value=72, step=4)\n",
        "    \n",
        "    self.encoder = Sequential([\n",
        "      Dense(dense_1_units, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(dense_2_units, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(dense_3_units, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(code_size, activation='relu')\n",
        "    ])\n",
        "    self.decoder = Sequential([\n",
        "      Dense(dense_4_units, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(dense_5_units, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(dense_6_units, activation='relu'),\n",
        "      Dropout(0.1),\n",
        "      Dense(output_units, activation='sigmoid')\n",
        "    ])\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    encoded = self.encoder(inputs)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "  model = AutoEncoderTuner(hp, 19)\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  model.compile(\n",
        "      loss='msle',\n",
        "      optimizer=Adam(learning_rate=hp_learning_rate),\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "QeYBC5fVhwUF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    directory='autoencoder',\n",
        "    project_name='tuning_autoencoder6'\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    x_train_scaled, \n",
        "    x_train_scaled, \n",
        "    epochs=20, \n",
        "    batch_size=16,\n",
        "    validation_data=(x_test_scaled, x_test_scaled)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4KHYR5hhxcR",
        "outputId": "c7bce60a-43c6-42df-ff8c-448d0aa5778e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 31 Complete [00h 03m 17s]\n",
            "val_loss: 0.011004282161593437\n",
            "\n",
            "Best val_loss So Far: 0.004620804451406002\n",
            "Total elapsed time: 00h 42m 39s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = [f'dense_{i}_units' for i in range(1,7)] + ['learning_rate']\n",
        "best_hyperparams = tuner.get_best_hyperparameters()\n",
        "for hps in hparams:\n",
        "  print(f\"{hps}: {best_hyperparams[0][hps]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFOt_bGPh5xC",
        "outputId": "6d4705b2-4377-46d6-cae2-61a07856a2d4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dense_1_units: 52\n",
            "dense_2_units: 48\n",
            "dense_3_units: 44\n",
            "dense_4_units: 52\n",
            "dense_5_units: 36\n",
            "dense_6_units: 72\n",
            "learning_rate: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models()[0]\n",
        "best_model.compile(loss='msle', optimizer=Adam(0.001))\n",
        "\n",
        "best_model.fit(\n",
        "    x_train_scaled,\n",
        "    x_train_scaled,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    validation_data=(x_test_scaled, x_test_scaled)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qU-6i5Bh-ZM",
        "outputId": "ba843a96-e973-4efe-c276-a21613c06d4e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0034 - val_loss: 0.0047\n",
            "Epoch 2/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0034 - val_loss: 0.0046\n",
            "Epoch 3/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0033 - val_loss: 0.0045\n",
            "Epoch 4/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0033 - val_loss: 0.0046\n",
            "Epoch 5/100\n",
            "3179/3179 [==============================] - 12s 4ms/step - loss: 0.0033 - val_loss: 0.0044\n",
            "Epoch 6/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0032 - val_loss: 0.0044\n",
            "Epoch 7/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0032 - val_loss: 0.0046\n",
            "Epoch 8/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0032 - val_loss: 0.0043\n",
            "Epoch 9/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0031 - val_loss: 0.0045\n",
            "Epoch 10/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0031 - val_loss: 0.0041\n",
            "Epoch 11/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0030 - val_loss: 0.0043\n",
            "Epoch 12/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0031 - val_loss: 0.0044\n",
            "Epoch 13/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0030 - val_loss: 0.0043\n",
            "Epoch 14/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0030 - val_loss: 0.0042\n",
            "Epoch 15/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0030 - val_loss: 0.0042\n",
            "Epoch 16/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0029 - val_loss: 0.0043\n",
            "Epoch 17/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0030 - val_loss: 0.0043\n",
            "Epoch 18/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0029 - val_loss: 0.0042\n",
            "Epoch 19/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0029 - val_loss: 0.0042\n",
            "Epoch 20/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0029 - val_loss: 0.0042\n",
            "Epoch 21/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0029 - val_loss: 0.0042\n",
            "Epoch 22/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0029 - val_loss: 0.0042\n",
            "Epoch 23/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0029 - val_loss: 0.0041\n",
            "Epoch 24/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0029 - val_loss: 0.0042\n",
            "Epoch 25/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0028 - val_loss: 0.0042\n",
            "Epoch 26/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0029 - val_loss: 0.0042\n",
            "Epoch 27/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0029 - val_loss: 0.0041\n",
            "Epoch 28/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 29/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 30/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0028 - val_loss: 0.0043\n",
            "Epoch 31/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0028 - val_loss: 0.0042\n",
            "Epoch 32/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0028 - val_loss: 0.0041\n",
            "Epoch 33/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0028 - val_loss: 0.0040\n",
            "Epoch 34/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0027 - val_loss: 0.0041\n",
            "Epoch 35/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0027 - val_loss: 0.0040\n",
            "Epoch 36/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0028 - val_loss: 0.0040\n",
            "Epoch 37/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0028 - val_loss: 0.0040\n",
            "Epoch 38/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0027 - val_loss: 0.0041\n",
            "Epoch 39/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0027 - val_loss: 0.0040\n",
            "Epoch 40/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0027 - val_loss: 0.0040\n",
            "Epoch 41/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0027 - val_loss: 0.0039\n",
            "Epoch 42/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0027 - val_loss: 0.0040\n",
            "Epoch 43/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0027 - val_loss: 0.0040\n",
            "Epoch 44/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0027 - val_loss: 0.0039\n",
            "Epoch 45/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0027 - val_loss: 0.0039\n",
            "Epoch 46/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0027 - val_loss: 0.0041\n",
            "Epoch 47/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0027 - val_loss: 0.0041\n",
            "Epoch 48/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0027 - val_loss: 0.0040\n",
            "Epoch 49/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0027 - val_loss: 0.0039\n",
            "Epoch 50/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0027 - val_loss: 0.0040\n",
            "Epoch 51/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0027 - val_loss: 0.0040\n",
            "Epoch 52/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0027 - val_loss: 0.0039\n",
            "Epoch 53/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0027 - val_loss: 0.0039\n",
            "Epoch 54/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0027 - val_loss: 0.0038\n",
            "Epoch 55/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0027 - val_loss: 0.0040\n",
            "Epoch 56/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 57/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0027 - val_loss: 0.0039\n",
            "Epoch 58/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0039\n",
            "Epoch 59/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 60/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0027 - val_loss: 0.0038\n",
            "Epoch 61/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 62/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 63/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0026 - val_loss: 0.0040\n",
            "Epoch 64/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0027 - val_loss: 0.0038\n",
            "Epoch 65/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0026 - val_loss: 0.0039\n",
            "Epoch 66/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0026 - val_loss: 0.0039\n",
            "Epoch 67/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 68/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 69/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 70/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 71/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 72/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 73/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0039\n",
            "Epoch 74/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 75/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0039\n",
            "Epoch 76/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 77/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 78/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 79/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 80/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 81/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0027 - val_loss: 0.0038\n",
            "Epoch 82/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 83/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 84/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 85/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0025 - val_loss: 0.0038\n",
            "Epoch 86/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0025 - val_loss: 0.0038\n",
            "Epoch 87/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 88/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 89/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 90/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 91/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0025 - val_loss: 0.0037\n",
            "Epoch 92/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n",
            "Epoch 93/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0025 - val_loss: 0.0037\n",
            "Epoch 94/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0026 - val_loss: 0.0036\n",
            "Epoch 95/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0026 - val_loss: 0.0040\n",
            "Epoch 96/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 97/100\n",
            "3179/3179 [==============================] - 9s 3ms/step - loss: 0.0025 - val_loss: 0.0037\n",
            "Epoch 98/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0026 - val_loss: 0.0037\n",
            "Epoch 99/100\n",
            "3179/3179 [==============================] - 11s 3ms/step - loss: 0.0025 - val_loss: 0.0038\n",
            "Epoch 100/100\n",
            "3179/3179 [==============================] - 10s 3ms/step - loss: 0.0026 - val_loss: 0.0038\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ae523ead0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_ = find_threshold(best_model, x_train_scaled)\n",
        "preds_ = get_predictions(best_model, x_test_scaled, threshold_)\n",
        "accuracy_score(preds_, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWSWSjXhiDud",
        "outputId": "e48e9b81-3c57-407e-b29e-de82fbeeaf4f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7139297522641238"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "4.AutoEncoder_DDoS_Detection_SDN_DDoS",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}